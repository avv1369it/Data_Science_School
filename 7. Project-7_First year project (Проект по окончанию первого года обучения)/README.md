# Project-7 "First year project / Проект по итогам первого года обучения"

## Оглавление<a id="nine"></a>

* [Описание проекта](#one)
* [Какой кейс решаем](#two)
* [Задачи проекта](#three)
* [Цели проекта](#four)
* [Метрики качества](#five)
* [Краткая информация о данных](#six)
* [Результат](#seven)
* [Выводы](#eight)

## Описание проекта<a id="one"></a>

Учебный проект направленный на отработку и закрепление полученных знаний в рамках обучения профессии Data Science в течение 1 года обучения. В течение данного периода были изучены следующие блоки и темы:

* Основные конструкции и структуры данных языка програмирования Python;
* Анализ, предобработка и визуализация данных с помощью специализированных библиотек: Pandas, Nympy, Matplotlib, Seaborn, Plotly;
* Работа с базами данных, SQL;
* Разведывательный анализ данных (EDA): алгоритмы и методы EDA, математическая статистика, статистические тесты, проектирование экспериментов;
* Введение в машинное обучение (ML): теория машинного обучения; обучение с учителем - задачи регрессии, класификации, обучение без учителя - кластеризация и техника понижения размерности; валидация данных и оценка моделей; отбор и селекция признаков; оптимизация гиперпараметров;
* Математика в машинном обучение: линейная алгебра в контексте линейных методов; математический анализ в контексте задач оптимизации; теория вероятности и наивный байесовский класификатор;
* Временные ряды (time series) и рекомендательные системы. Введение в Deep Learning и Data Engineering;
* Работа с GitHub и Kaggle;
* Интеграция решений в продакшн.

⬆️[к оглавлению](#nine)

## Какой кейс решаем<a id="two"></a>

В крупном агенстве недвижимости существует проблема - риэлторы тратят катострофически много времени на сортировку объявлений и поиск выгодных предложений, что влияет на скорость реакции и качество анализа, который не соответствцет уровню конкурентов. Это, в свою очередь, сказывается на финансовых показателях агенства недвижимости.

⬆️[к оглавлению](#nine)

## Задачи проекта<a id="three"></a>

**Бизнес-задача:** разработать сервис, который позволил бы обойти конкурентов по скорости и качеству совершения сделок.

**Техническая задача (как для специалиста в Data Science):** разработать модель для предсказания стоимости домов на основе истории предложений.

⬆️[к оглавлению](#nine)

## Цели проекта<a id="four"></a>

1. *Провести первичную обработку данных* - необходимо обработать пропуски и выбросы в данных для дальнейшей работы с ними;
2. *Провести разведывательный анализ данных (EDA)* - необходимо исследовать данные, определить первые закономерности и выдвинуть гипотезы;
3. *Выполнить отбор и преобразование признаков* - необходимо перекодировать и преобразовать признаки для решения задачи регрессии;
4. *Спроектировать новые признаки* с помощью Feature Engineering и выявить наиболее значимые при построении модели;
5. *Исследовать предоставленные данные* и выявить закономерности;
6. *Построить несколько моделей* и выбрать из них наилучшую по определенной метрике;
7. *Построить предсказания* - определить алгоритм для построения модели с более качественными предсказаниями, доработать предсказания и прогнозы.

⬆️[к оглавлению](#nine)

## Метрики качества работы<a id="five"></a>

1. ***Анализ и обработка данных:***
   * Произведена подготовка и очистка данных - подготовлен dataset и проведен его качественный EDA;
   * Проведен статистический анализ данных - выводы подтверждаются статистическими тестами и данная информация используется в решении;
   * Использование инструментов аизуализации - активно используется визуализация и выводы из нее в решениях;
2. ***Применение ML и DL***:
   * Наличие baseline, проверка способов решения задачи - проанализированы способы решения задачи, подготовлен baseline для решения и показано превосходство предложенного решения;
   * Соответствие выбранных методов требованиям задачи - методы соответствуют задачи и их использование позволяет добиться существенного улучшения качества;
   * Комплексность методов (применение различных моделей, энкодеров, ансамблей и т.д.) - корректно используется комплекс из современных методов ML, приводится сравнение результатов и это адекватно решаемой задаче;
   * Возможность реализации предложенного решения в продакшн - предложенное решение или реализовано или может быть реализовано в продакшн;
   * Использование дополнительных инструментов вне курса - активно используются инструменты, которые не были рассмотрены в курсе и это улучшает качество работы;
3. ***Оформление кода:***
   * Правильность, понятность, читабельность, документация к коду - код верный, соответствует стандартам оформления, имеется документация;
4. ***Проект размещен на GitHub.***

⬆️[к оглавлению](#nine)

## Краткая информация о данных<a id="six"></a>

Заказчико предоставлен ***dataset*** с данными по объектам недвижимости data.csv, который находится в папке data. Так как данные имеют большой размер их можно скачать по [ссылке](https://disk.yandex.ru/d/LVLceiWRzByFlA).

⬆️[к оглавлению](#nine)

## Результат<a id="seven"></a>

* Подготовлен Jupyter Notebook - FTProject(GitHub)_full.ipynb;
* Подготовлены Jupiter Notebook c рассматриваемыми моделями в проекте (14). Так как часть имеет большой размер, полный комплект можно скачать по [ссылке](https://disk.yandex.ru/d/LVLceiWRzByFlA).
* Подготовлена папка model в которой сохранены рассматриваемые модели. Так как модели имеет очень большой размер, полный комплект можно скачать по [ссылке](https://disk.yandex.ru/d/LVLceiWRzByFlA).

⬆️[к оглавлению](#nine)

## Выводы<a id="eight"></a>

**Что сделано:**

1. Погрузился в обработку очень плохих данных (на мой взгляд - очень плохие), есть понимание когда уважаемые менторы SkillFactory говорят, что 70% времени это обработка данных;
2. На этапе предобработки данных не стал сильно обрезать выбросы, с целью сохранить как можно больший объем данных;
3. Два признака взял и векторизовал, не нашел лучшего метода, а может просто не хватило времени. Просьба к тем, кто будет смотреть и оценивать написать комментарии, что можно было сделать с ними, кроме как расшить через кодирование или векторизовать;
4. Старался рассмотреть максимально все модели Regression, но очень быстро понял, что в рамках данной работы и отведенного времени, это не возможно;
5. Погрузился в работу с библиотеками по подбору гиперпараметров и понял, что это еще та "черная дыра" по пожиранию времени и ресурсов. Понравилась библиотека Optuna, считаю ее пока лучшей по критерию время - затраты - качество;
6. Разочаровался в Нейросети (своей), так как было ощущение, что она сотворит чудо.-) Наверно мало знаний и навыков, продолжим учиться;
7. Очень понравилась библиотека H2O - простая, доступная (в рамках того что делал). Не все получилось с LAMA, но так как это СБЕР продолжу работать.

**Что не получилось:**

1. Начинал за "здравие", закончил за "упокой": такое ощущение, что все что учил в течение года - забыл; чем больше погружаешься, тем больше ощущение, что почти ни чего не знаешь;
2. Ни чего не сделал в части продакшин и деплой модели, хотел написать веб-приложение на Flask, но уже все сроки просрочены (вернусь позже).

**Резюме:**

1. Лучшие показатели MAE и MAPE (на мой взгляд они более понятны будут для заказчика) достигнуты с помощью модели ***StackingRegressor_1***, но в реальной жизни я бы продолжил работать с моделью ***XGBosstRegressorOptuna*** по причине легкости ее перенастройки, обучения, адаптации и т.д.

⬆️[к оглавлению](#nine)

Если информация по этому проекту покажется вам интересной или полезной, то я буду очень вам благодарен, если отметите репозиторий и профиль.
⭐️⭐️⭐️⭐️⭐️
